{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/prasadposture121/randomforestclassifier?scriptVersionId=109008934\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# RandomForestClassifier() for Everything\n\nI'm trying to create an application which takes train data (to train the model), test data (to make predictions on) and sample submissions (since it is given in every  kaggle competition) as the inputs, and gives output in the form of predictions it made on test data.\n\nMy aim is to make the code reusable so that it works for any data given to it, and the little we have to do is to give those required inputs manually and the applications does all the needful which includes filling missing values, encoding categorical attributes, dropping unneccessary columns and much more.\n\nI'm open for all types of suggestions and reviews, feel free to comment.   \nThank You!","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# House Price Predictions\nWe will the re-usable code for making predictions on housing price. We will also see more examples.","metadata":{"execution":{"iopub.status.busy":"2022-10-03T16:47:09.432669Z","iopub.execute_input":"2022-10-03T16:47:09.433193Z","iopub.status.idle":"2022-10-03T16:47:10.13619Z","shell.execute_reply.started":"2022-10-03T16:47:09.433096Z","shell.execute_reply":"2022-10-03T16:47:10.134931Z"}}},{"cell_type":"code","source":"#importing requied libraries\nimport pandas as pd\nimport numpy as np\nimport warnings\nprint('Libraries Imported') #making sure the libraries are imported\n#filtering the warnings cuz presence of warnigs would make the output messier\nwarnings.filterwarnings('ignore')\n\n\n#loading the train data (with user input)\ntrain_data=input('Enter the train data :')\n#for application this has to be like 'upload your file' kinda option\ntrain=pd.read_csv(train_data)\n\n#loading the test data (with user input)\ntest_data=input('Enter the test data :')\ntest=pd.read_csv(test_data)\n\n#loading the sample submission to save our predictions\n#the sample submissions is given all the time along with test and train data\n#but in case it isnt given we need to put it in try-except block\n#we will have to make changes in the saving method as well\n#new comment : assuming that the sample submission is already given\n#cause it makes things lot easier and this program is written while considering the kaggle competetions\n#where the sample submission is always given\nsample_data=input('Enter the sample submission :')\nsample=pd.read_csv(sample_data)\nprint('Data Loaded!') #making sure the data is loaded\n\n#getting stastical information of the numeric variables\n#storing it into a dataframe for using it later for filling missing values and \n#seperating numeric columns form categorical columns\ntrain_describe=pd.DataFrame(train.describe())\n\n#doing the same for test data\ntest_describe=pd.DataFrame(test.describe())\n\n#describing with category\n#we will put it in try...except block since some of the data many not have categorical attributes\n#saving the stastical information will be useful while filling the missing values\ntry:\n    train_describe_cat=pd.DataFrame(train.describe(include=['O']))\n    test_describe_cat=pd.DataFrame(test.describe(include=['O']))\nexcept Exception as e:\n    pass\n\n#We will fill these missing values -\n#using median for numerical data\n#using top for categorical data\n\n#getting the list of numeric columns from stastical description\ntrain_describe_columns=list(train_describe.columns)\ntest_describe_columns=list(test_describe.columns)\n\n#getting the list of categorical columns from the stastical description\ntry:\n    train_describe_cat_columns=list(train_describe_cat.columns)\n    test_describe_cat_columns=list(test_describe_cat.columns)\nexcept:\n    pass\n\n#filling the missing values for numerical values with the median\nfor i in train_describe_columns:\n    train[i].fillna(train[i].median(), inplace=True)\nfor i in test_describe_columns:\n    test[i].fillna(test[i].median(), inplace=True)\n    \n#filling the missing values for categorical values with the mostly reccurring value\ntry:\n    for i in train_describe_cat_columns:\n        train[i].fillna(train_describe_cat.iloc[2,train_describe_cat_columns.index(i)], inplace=True)\n    for i in test_describe_cat_columns:\n        test[i].fillna(test_describe_cat.iloc[2,test_describe_cat_columns.index(i)], inplace=True)\nexcept:\n    pass\nprint('We filled the missing values!') #making sure the missing values are filled\n\n#setting ID's\n#We will put it in try except block since sometimes we dont have seperate data\ntry:\n    for i in list(train.columns):\n        if 'Id' in i: #using the fact that infact Id have string 'Id' in their name eg PassengerID.\n            Id=i\n            print('The Id of data is :', Id)\n        else:\n            pass\n    train.set_index(Id ,inplace=True)\n    test.set_index(Id ,inplace=True)\nexcept:\n    pass\n\n#we will drop the categorical columns which contain unique values with proportion 0.1 or more \n#to that of total value count\ntry:\n    if Id in train_describe_cat_columns:\n        train_describe_cat_columns.remove(Id)\n    columns_to_be_dropped=[]\n    for i in train_describe_cat_columns:\n        a=test_describe_cat.iloc[1,test_describe_cat_columns.index(i)]/test_describe_cat.iloc[0,test_describe_cat_columns.index(i)]\n        a=float(a)\n        if a>0.1:\n            columns_to_be_dropped.append(i)\n    train.drop(columns=columns_to_be_dropped, inplace=True)\n    test.drop(columns=columns_to_be_dropped, inplace=True)\n    train_describe_cat=pd.DataFrame(train.describe(include=['O']))\n    test_describe_cat=pd.DataFrame(test.describe(include=['O']))\n    train_describe_cat_columns=list(train_describe_cat.columns)\n    test_describe_cat_columns=list(test_describe_cat.columns)\n    print('Columns to be dropped :',columns_to_be_dropped)\n    \n#Label Encoding\n#Labelling the categorical values with numbers so that machine could understand it\n#putting it try-except block because we may not have categorical values\n\n    from sklearn.preprocessing import LabelEncoder\n    for i in train_describe_cat_columns:\n        le=LabelEncoder()\n        arr=np.concatenate((train[i], test[i])).astype(str)\n        le.fit(arr)\n        train[i]=le.transform(train[i].astype(str))\n        test[i]=le.transform(test[i].astype(str))\nexcept:\n    pass\n\n#Getting the target variable aka the variable we gonna predict\n#here we are using the fact that the target variable wouldn't be present in the test data\na=set(train.columns)\nb=set(test.columns)\nc=list(a-b)\nlabel=c[0]\nprint('Target variable is :', label) #showing the target variable\n\n#assiging dependent and independent variables\nX=train.drop(label,axis=1)\ny=train[label]\n\n#train_test_split()\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=4)\n\n#Modeling\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(X_train,y_train)\npred_y=rf.predict(X_val)\nfrom sklearn.metrics import accuracy_score\nprint('The accuracy is :',accuracy_score(y_val.values,pred_y))\n\n#making predictions on test data\ny_pred=rf.predict(test)\n\n#saving the submissions in the form of pandas dataframe\n#submission=pd.DataFrame({label:y_pred},index=test.index) : freq used in older versions\nsample_columns=list(sample.columns)\nsample[sample_columns[1]]=y_pred\nfile_name=input('Enter the title of submission :')\nsample.to_csv(file_name, index=False)\nprint('SUBMISSIONS SAVED SUCCESSFULLY!!!')\nsample.head()#making sure that the submission is saved.","metadata":{"execution":{"iopub.status.busy":"2022-10-24T16:37:30.65834Z","iopub.execute_input":"2022-10-24T16:37:30.658799Z","iopub.status.idle":"2022-10-24T16:38:03.40583Z","shell.execute_reply.started":"2022-10-24T16:37:30.658764Z","shell.execute_reply":"2022-10-24T16:38:03.404781Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Libraries Imported\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the train data : ../input/house-prices-advanced-regression-techniques/train.csv\nEnter the test data : ../input/house-prices-advanced-regression-techniques/test.csv\nEnter the sample submission : ../input/house-prices-advanced-regression-techniques/sample_submission.csv\n"},{"name":"stdout","text":"Data Loaded!\nWe filled the missing values!\nThe Id of data is : Id\nColumns to be dropped : ['PoolQC']\nTarget variable is : SalePrice\nThe accuracy is : 0.01643835616438356\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the title of submission : housing.csv\n"},{"name":"stdout","text":"SUBMISSIONS SAVED SUCCESSFULLY!!!\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"     Id  SalePrice\n0  1461     125000\n1  1462     164900\n2  1463     192000\n3  1464     189000\n4  1465     180000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1461</td>\n      <td>125000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1462</td>\n      <td>164900</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1463</td>\n      <td>192000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1464</td>\n      <td>189000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1465</td>\n      <td>180000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Titanic\nNow will use the same code for making predictions on titanic dataset.","metadata":{}},{"cell_type":"code","source":"#importing requied libraries\nimport pandas as pd\nimport numpy as np\nimport warnings\nprint('Libraries Imported') #making sure the libraries are imported\n#filtering the warnings cuz presence of warnigs would make the output messier\nwarnings.filterwarnings('ignore')\n\n\n#loading the train data (with user input)\ntrain_data=input('Enter the train data :')\n#for application this has to be like 'upload your file' kinda option\ntrain=pd.read_csv(train_data)\n\n#loading the test data (with user input)\ntest_data=input('Enter the test data :')\ntest=pd.read_csv(test_data)\n\n#loading the sample submission to save our predictions\n#the sample submissions is given all the time along with test and train data\n#but in case it isnt given we need to put it in try-except block\n#we will have to make changes in the saving method as well\n#new comment : assuming that the sample submission is already given\n#cause it makes things lot easier and this program is written while considering the kaggle competetions\n#where the sample submission is always given\nsample_data=input('Enter the sample submission :')\nsample=pd.read_csv(sample_data)\nprint('Data Loaded!') #making sure the data is loaded\n\n#getting stastical information of the numeric variables\n#storing it into a dataframe for using it later for filling missing values and \n#seperating numeric columns form categorical columns\ntrain_describe=pd.DataFrame(train.describe())\n\n#doing the same for test data\ntest_describe=pd.DataFrame(test.describe())\n\n#describing with category\n#we will put it in try...except block since some of the data many not have categorical attributes\n#saving the stastical information will be useful while filling the missing values\ntry:\n    train_describe_cat=pd.DataFrame(train.describe(include=['O']))\n    test_describe_cat=pd.DataFrame(test.describe(include=['O']))\nexcept Exception as e:\n    pass\n\n#We will fill these missing values -\n#using median for numerical data\n#using top for categorical data\n\n#getting the list of numeric columns from stastical description\ntrain_describe_columns=list(train_describe.columns)\ntest_describe_columns=list(test_describe.columns)\n\n#getting the list of categorical columns from the stastical description\ntry:\n    train_describe_cat_columns=list(train_describe_cat.columns)\n    test_describe_cat_columns=list(test_describe_cat.columns)\nexcept:\n    pass\n\n#filling the missing values for numerical values with the median\nfor i in train_describe_columns:\n    train[i].fillna(train[i].median(), inplace=True)\nfor i in test_describe_columns:\n    test[i].fillna(test[i].median(), inplace=True)\n    \n#filling the missing values for categorical values with the mostly reccurring value\ntry:\n    for i in train_describe_cat_columns:\n        train[i].fillna(train_describe_cat.iloc[2,train_describe_cat_columns.index(i)], inplace=True)\n    for i in test_describe_cat_columns:\n        test[i].fillna(test_describe_cat.iloc[2,test_describe_cat_columns.index(i)], inplace=True)\nexcept:\n    pass\nprint('We filled the missing values!') #making sure the missing values are filled\n\n#setting ID's\n#We will put it in try except block since sometimes we dont have seperate data\ntry:\n    for i in list(train.columns):\n        if 'Id' in i: #using the fact that infact Id have string 'Id' in their name eg PassengerID.\n            Id=i\n            print('The Id of data is :', Id)\n        else:\n            pass\n    train.set_index(Id ,inplace=True)\n    test.set_index(Id ,inplace=True)\nexcept:\n    pass\n\n#we will drop the categorical columns which contain unique values with proportion 0.1 or more \n#to that of total value count\ntry:\n    if Id in train_describe_cat_columns:\n        train_describe_cat_columns.remove(Id)\n    columns_to_be_dropped=[]\n    for i in train_describe_cat_columns:\n        a=test_describe_cat.iloc[1,test_describe_cat_columns.index(i)]/test_describe_cat.iloc[0,test_describe_cat_columns.index(i)]\n        a=float(a)\n        if a>0.1:\n            columns_to_be_dropped.append(i)\n    train.drop(columns=columns_to_be_dropped, inplace=True)\n    test.drop(columns=columns_to_be_dropped, inplace=True)\n    train_describe_cat=pd.DataFrame(train.describe(include=['O']))\n    test_describe_cat=pd.DataFrame(test.describe(include=['O']))\n    train_describe_cat_columns=list(train_describe_cat.columns)\n    test_describe_cat_columns=list(test_describe_cat.columns)\n    print('Columns to be dropped :',columns_to_be_dropped)\n    \n#Label Encoding\n#Labelling the categorical values with numbers so that machine could understand it\n#putting it try-except block because we may not have categorical values\n\n    from sklearn.preprocessing import LabelEncoder\n    for i in train_describe_cat_columns:\n        le=LabelEncoder()\n        arr=np.concatenate((train[i], test[i])).astype(str)\n        le.fit(arr)\n        train[i]=le.transform(train[i].astype(str))\n        test[i]=le.transform(test[i].astype(str))\nexcept:\n    pass\n\n#Getting the target variable aka the variable we gonna predict\n#here we are using the fact that the target variable wouldn't be present in the test data\na=set(train.columns)\nb=set(test.columns)\nc=list(a-b)\nlabel=c[0]\nprint('Target variable is :', label) #showing the target variable\n\n#assiging dependent and independent variables\nX=train.drop(label,axis=1)\ny=train[label]\n\n#train_test_split()\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=4)\n\n#Modeling\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(X_train,y_train)\npred_y=rf.predict(X_val)\nfrom sklearn.metrics import accuracy_score\nprint('The accuracy is :',accuracy_score(y_val.values,pred_y))\n\n#making predictions on test data\ny_pred=rf.predict(test)\n\n#saving the submissions in the form of pandas dataframe\n#submission=pd.DataFrame({label:y_pred},index=test.index) : freq used in older versions\nsample_columns=list(sample.columns)\nsample[sample_columns[1]]=y_pred\nfile_name=input('Enter the title of submission :')\nsample.to_csv(file_name, index=False)\nprint('SUBMISSIONS SAVED SUCCESSFULLY!!!')\nsample.head()#making sure that the submission is saved.","metadata":{"execution":{"iopub.status.busy":"2022-10-24T16:38:15.798317Z","iopub.execute_input":"2022-10-24T16:38:15.798732Z","iopub.status.idle":"2022-10-24T16:38:43.344168Z","shell.execute_reply.started":"2022-10-24T16:38:15.798696Z","shell.execute_reply":"2022-10-24T16:38:43.34289Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Libraries Imported\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the train data : ../input/titanic/train.csv\nEnter the test data : ../input/titanic/test.csv\nEnter the sample submission : ../input/titanic/gender_submission.csv\n"},{"name":"stdout","text":"Data Loaded!\nWe filled the missing values!\nThe Id of data is : PassengerId\nColumns to be dropped : ['Name', 'Ticket', 'Cabin']\nTarget variable is : Survived\nThe accuracy is : 0.8251121076233184\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the title of submission : titanic.csv\n"},{"name":"stdout","text":"SUBMISSIONS SAVED SUCCESSFULLY!!!\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived\n0          892         0\n1          893         0\n2          894         0\n3          895         0\n4          896         1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Digit Recognizer\nLet's try our code on something which doesn't have categorical data or missing values","metadata":{}},{"cell_type":"code","source":"#importing requied libraries\nimport pandas as pd\nimport numpy as np\nimport warnings\nprint('Libraries Imported') #making sure the libraries are imported\n#filtering the warnings cuz presence of warnigs would make the output messier\nwarnings.filterwarnings('ignore')\n\n\n#loading the train data (with user input)\ntrain_data=input('Enter the train data :')\n#for application this has to be like 'upload your file' kinda option\ntrain=pd.read_csv(train_data)\n\n#loading the test data (with user input)\ntest_data=input('Enter the test data :')\ntest=pd.read_csv(test_data)\n\n#loading the sample submission to save our predictions\n#the sample submissions is given all the time along with test and train data\n#but in case it isnt given we need to put it in try-except block\n#we will have to make changes in the saving method as well\n#new comment : assuming that the sample submission is already given\n#cause it makes things lot easier and this program is written while considering the kaggle competetions\n#where the sample submission is always given\nsample_data=input('Enter the sample submission :')\nsample=pd.read_csv(sample_data)\nprint('Data Loaded!') #making sure the data is loaded\n\n#getting stastical information of the numeric variables\n#storing it into a dataframe for using it later for filling missing values and \n#seperating numeric columns form categorical columns\ntrain_describe=pd.DataFrame(train.describe())\n\n#doing the same for test data\ntest_describe=pd.DataFrame(test.describe())\n\n#describing with category\n#we will put it in try...except block since some of the data many not have categorical attributes\n#saving the stastical information will be useful while filling the missing values\ntry:\n    train_describe_cat=pd.DataFrame(train.describe(include=['O']))\n    test_describe_cat=pd.DataFrame(test.describe(include=['O']))\nexcept Exception as e:\n    pass\n\n#We will fill these missing values -\n#using median for numerical data\n#using top for categorical data\n\n#getting the list of numeric columns from stastical description\ntrain_describe_columns=list(train_describe.columns)\ntest_describe_columns=list(test_describe.columns)\n\n#getting the list of categorical columns from the stastical description\ntry:\n    train_describe_cat_columns=list(train_describe_cat.columns)\n    test_describe_cat_columns=list(test_describe_cat.columns)\nexcept:\n    pass\n\n#filling the missing values for numerical values with the median\nfor i in train_describe_columns:\n    train[i].fillna(train[i].median(), inplace=True)\nfor i in test_describe_columns:\n    test[i].fillna(test[i].median(), inplace=True)\n    \n#filling the missing values for categorical values with the mostly reccurring value\ntry:\n    for i in train_describe_cat_columns:\n        train[i].fillna(train_describe_cat.iloc[2,train_describe_cat_columns.index(i)], inplace=True)\n    for i in test_describe_cat_columns:\n        test[i].fillna(test_describe_cat.iloc[2,test_describe_cat_columns.index(i)], inplace=True)\nexcept:\n    pass\nprint('We filled the missing values!') #making sure the missing values are filled\n\n#setting ID's\n#We will put it in try except block since sometimes we dont have seperate data\ntry:\n    for i in list(train.columns):\n        if 'Id' in i: #using the fact that infact Id have string 'Id' in their name eg PassengerID.\n            Id=i\n            print('The Id of data is :', Id)\n        else:\n            pass\n    train.set_index(Id ,inplace=True)\n    test.set_index(Id ,inplace=True)\nexcept:\n    pass\n\n#we will drop the categorical columns which contain unique values with proportion 0.1 or more \n#to that of total value count\ntry:\n    if Id in train_describe_cat_columns:\n        train_describe_cat_columns.remove(Id)\n    columns_to_be_dropped=[]\n    for i in train_describe_cat_columns:\n        a=test_describe_cat.iloc[1,test_describe_cat_columns.index(i)]/test_describe_cat.iloc[0,test_describe_cat_columns.index(i)]\n        a=float(a)\n        if a>0.1:\n            columns_to_be_dropped.append(i)\n    train.drop(columns=columns_to_be_dropped, inplace=True)\n    test.drop(columns=columns_to_be_dropped, inplace=True)\n    train_describe_cat=pd.DataFrame(train.describe(include=['O']))\n    test_describe_cat=pd.DataFrame(test.describe(include=['O']))\n    train_describe_cat_columns=list(train_describe_cat.columns)\n    test_describe_cat_columns=list(test_describe_cat.columns)\n    print('Columns to be dropped :',columns_to_be_dropped)\n    \n#Label Encoding\n#Labelling the categorical values with numbers so that machine could understand it\n#putting it try-except block because we may not have categorical values\n\n    from sklearn.preprocessing import LabelEncoder\n    for i in train_describe_cat_columns:\n        le=LabelEncoder()\n        arr=np.concatenate((train[i], test[i])).astype(str)\n        le.fit(arr)\n        train[i]=le.transform(train[i].astype(str))\n        test[i]=le.transform(test[i].astype(str))\nexcept:\n    pass\n\n#Getting the target variable aka the variable we gonna predict\n#here we are using the fact that the target variable wouldn't be present in the test data\na=set(train.columns)\nb=set(test.columns)\nc=list(a-b)\nlabel=c[0]\nprint('Target variable is :', label) #showing the target variable\n\n#assiging dependent and independent variables\nX=train.drop(label,axis=1)\ny=train[label]\n\n#train_test_split()\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=4)\n\n#Modeling\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(X_train,y_train)\npred_y=rf.predict(X_val)\nfrom sklearn.metrics import accuracy_score\nprint('The accuracy is :',accuracy_score(y_val.values,pred_y))\n\n#making predictions on test data\ny_pred=rf.predict(test)\n\n#saving the submissions in the form of pandas dataframe\n#submission=pd.DataFrame({label:y_pred},index=test.index) : freq used in older versions\nsample_columns=list(sample.columns)\nsample[sample_columns[1]]=y_pred\nfile_name=input('Enter the title of submission :')\nsample.to_csv(file_name, index=False)\nprint('SUBMISSIONS SAVED SUCCESSFULLY!!!')\nsample.head()#making sure that the submission is saved.","metadata":{"execution":{"iopub.status.busy":"2022-10-24T16:38:59.403124Z","iopub.execute_input":"2022-10-24T16:38:59.404255Z","iopub.status.idle":"2022-10-24T16:40:15.464759Z","shell.execute_reply.started":"2022-10-24T16:38:59.404215Z","shell.execute_reply":"2022-10-24T16:40:15.463541Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Libraries Imported\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the train data : ../input/digit-recognizer/train.csv\nEnter the test data : ../input/digit-recognizer/test.csv\nEnter the sample submission : ../input/digit-recognizer/sample_submission.csv\n"},{"name":"stdout","text":"Data Loaded!\nWe filled the missing values!\nTarget variable is : label\nThe accuracy is : 0.9601904761904761\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the title of submission : digit_recognizer.csv\n"},{"name":"stdout","text":"SUBMISSIONS SAVED SUCCESSFULLY!!!\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"   ImageId  Label\n0        1      2\n1        2      0\n2        3      9\n3        4      9\n4        5      3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Spaceship Titanic\nThis is similiar as that of titanic, but this had me made special changes in the code to make it work for any general dataset.","metadata":{}},{"cell_type":"code","source":"#importing requied libraries\nimport pandas as pd\nimport numpy as np\nimport warnings\nprint('Libraries Imported') #making sure the libraries are imported\n#filtering the warnings cuz presence of warnigs would make the output messier\nwarnings.filterwarnings('ignore')\n\n\n#loading the train data (with user input)\ntrain_data=input('Enter the train data :')\n#for application this has to be like 'upload your file' kinda option\ntrain=pd.read_csv(train_data)\n\n#loading the test data (with user input)\ntest_data=input('Enter the test data :')\ntest=pd.read_csv(test_data)\n\n#loading the sample submission to save our predictions\n#the sample submissions is given all the time along with test and train data\n#but in case it isnt given we need to put it in try-except block\n#we will have to make changes in the saving method as well\n#new comment : assuming that the sample submission is already given\n#cause it makes things lot easier and this program is written while considering the kaggle competetions\n#where the sample submission is always given\nsample_data=input('Enter the sample submission :')\nsample=pd.read_csv(sample_data)\nprint('Data Loaded!') #making sure the data is loaded\n\n#getting stastical information of the numeric variables\n#storing it into a dataframe for using it later for filling missing values and \n#seperating numeric columns form categorical columns\ntrain_describe=pd.DataFrame(train.describe())\n\n#doing the same for test data\ntest_describe=pd.DataFrame(test.describe())\n\n#describing with category\n#we will put it in try...except block since some of the data many not have categorical attributes\n#saving the stastical information will be useful while filling the missing values\ntry:\n    train_describe_cat=pd.DataFrame(train.describe(include=['O']))\n    test_describe_cat=pd.DataFrame(test.describe(include=['O']))\nexcept Exception as e:\n    pass\n\n#We will fill these missing values -\n#using median for numerical data\n#using top for categorical data\n\n#getting the list of numeric columns from stastical description\ntrain_describe_columns=list(train_describe.columns)\ntest_describe_columns=list(test_describe.columns)\n\n#getting the list of categorical columns from the stastical description\ntry:\n    train_describe_cat_columns=list(train_describe_cat.columns)\n    test_describe_cat_columns=list(test_describe_cat.columns)\nexcept:\n    pass\n\n#filling the missing values for numerical values with the median\nfor i in train_describe_columns:\n    train[i].fillna(train[i].median(), inplace=True)\nfor i in test_describe_columns:\n    test[i].fillna(test[i].median(), inplace=True)\n    \n#filling the missing values for categorical values with the mostly reccurring value\ntry:\n    for i in train_describe_cat_columns:\n        train[i].fillna(train_describe_cat.iloc[2,train_describe_cat_columns.index(i)], inplace=True)\n    for i in test_describe_cat_columns:\n        test[i].fillna(test_describe_cat.iloc[2,test_describe_cat_columns.index(i)], inplace=True)\nexcept:\n    pass\nprint('We filled the missing values!') #making sure the missing values are filled\n\n#setting ID's\n#We will put it in try except block since sometimes we dont have seperate data\ntry:\n    for i in list(train.columns):\n        if 'Id' in i: #using the fact that infact Id have string 'Id' in their name eg PassengerID.\n            Id=i\n            print('The Id of data is :', Id)\n        else:\n            pass\n    train.set_index(Id ,inplace=True)\n    test.set_index(Id ,inplace=True)\nexcept:\n    pass\n\n#we will drop the categorical columns which contain unique values with proportion 0.1 or more \n#to that of total value count\ntry:\n    if Id in train_describe_cat_columns:\n        train_describe_cat_columns.remove(Id)\n    columns_to_be_dropped=[]\n    for i in train_describe_cat_columns:\n        a=test_describe_cat.iloc[1,test_describe_cat_columns.index(i)]/test_describe_cat.iloc[0,test_describe_cat_columns.index(i)]\n        a=float(a)\n        if a>0.1:\n            columns_to_be_dropped.append(i)\n    train.drop(columns=columns_to_be_dropped, inplace=True)\n    test.drop(columns=columns_to_be_dropped, inplace=True)\n    train_describe_cat=pd.DataFrame(train.describe(include=['O']))\n    test_describe_cat=pd.DataFrame(test.describe(include=['O']))\n    train_describe_cat_columns=list(train_describe_cat.columns)\n    test_describe_cat_columns=list(test_describe_cat.columns)\n    print('Columns to be dropped :',columns_to_be_dropped)\n    \n#Label Encoding\n#Labelling the categorical values with numbers so that machine could understand it\n#putting it try-except block because we may not have categorical values\n\n    from sklearn.preprocessing import LabelEncoder\n    for i in train_describe_cat_columns:\n        le=LabelEncoder()\n        arr=np.concatenate((train[i], test[i])).astype(str)\n        le.fit(arr)\n        train[i]=le.transform(train[i].astype(str))\n        test[i]=le.transform(test[i].astype(str))\nexcept:\n    pass\n\n#Getting the target variable aka the variable we gonna predict\n#here we are using the fact that the target variable wouldn't be present in the test data\na=set(train.columns)\nb=set(test.columns)\nc=list(a-b)\nlabel=c[0]\nprint('Target variable is :', label) #showing the target variable\n\n#assiging dependent and independent variables\nX=train.drop(label,axis=1)\ny=train[label]\n\n#train_test_split()\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=4)\n\n#Modeling\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(X_train,y_train)\npred_y=rf.predict(X_val)\nfrom sklearn.metrics import accuracy_score\nprint('The accuracy is :',accuracy_score(y_val.values,pred_y))\n\n#making predictions on test data\ny_pred=rf.predict(test)\n\n#saving the submissions in the form of pandas dataframe\n#submission=pd.DataFrame({label:y_pred},index=test.index) : freq used in older versions\nsample_columns=list(sample.columns)\nsample[sample_columns[1]]=y_pred\nfile_name=input('Enter the title of submission :')\nsample.to_csv(file_name, index=False)\nprint('SUBMISSIONS SAVED SUCCESSFULLY!!!')\nsample.head()#making sure that the submission is saved.","metadata":{"execution":{"iopub.status.busy":"2022-10-24T16:40:21.859292Z","iopub.execute_input":"2022-10-24T16:40:21.859866Z","iopub.status.idle":"2022-10-24T16:40:56.924069Z","shell.execute_reply.started":"2022-10-24T16:40:21.859824Z","shell.execute_reply":"2022-10-24T16:40:56.922769Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Libraries Imported\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the train data : ../input/spaceship-titanic/train.csv\nEnter the test data : ../input/spaceship-titanic/test.csv\nEnter the sample submission : ../input/spaceship-titanic/sample_submission.csv\n"},{"name":"stdout","text":"Data Loaded!\nWe filled the missing values!\nThe Id of data is : PassengerId\nColumns to be dropped : ['Cabin', 'Name']\nTarget variable is : Transported\nThe accuracy is : 0.7773689052437902\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the title of submission : spaceship.csv\n"},{"name":"stdout","text":"SUBMISSIONS SAVED SUCCESSFULLY!!!\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"  PassengerId  Transported\n0     0013_01         True\n1     0018_01        False\n2     0019_01         True\n3     0021_01         True\n4     0023_01         True","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Transported</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0013_01</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0018_01</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0019_01</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0021_01</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0023_01</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Here I have directly used `RandomForestClassifier()` for multiple datasets while using the same program over and over again to make pre-processing on the data, later, make predictions on it and then save it in `.csv` file. If you want to know more about the `RandomForestClassifier()` - The Supervised Machine Learning Algorithm, visit the link given below:\n[RandomForestClassifier()](https://www.analyticsvidhya.com/blog/2021/06/understanding-random-forest/)","metadata":{}},{"cell_type":"markdown","source":"I feel, I have made enough changes to make it more efficient, but you have any suggestions please let me know in the comments. If you are trying to take part in kaggle competitions but don't know where to start this code and the datasets will surely be useful. All that you have to is enter the respective links of the train data, test data and sample submission, and in the output you will get readily  saved predictions to submit. Feel free to make any changes to make those predictions more accurate and please let me know the changs you made that improved your accuracy. A Big Thank You!","metadata":{}}]}